{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part -1 \n",
    "\n",
    "#### Use OpenCV or any other library for input pipeline (transformations, augmentations, rotation, etc..)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mndata = MNIST('samples')\n",
    "images, labels = mndata.load_training()\n",
    "images1, labels1 = mndata.load_testing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting list into numpy arrays\n",
    "train_x=np.array(images)\n",
    "train_y=np.array(labels)\n",
    "test_x=np.array(images1)\n",
    "test_y=np.array(labels1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshaping in Conventional Form\n",
    "train_x=train_x.T\n",
    "test_x=test_x.T\n",
    "train_y=train_y.reshape(1,60000)\n",
    "test_y=test_y.reshape(1,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Printing Image\n",
    "plt.imshow(train_x[:,0].reshape((28,28)), interpolation='nearest',cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Necessary Libraries for Transformation\n",
    "from skimage.transform import rescale\n",
    "from skimage.transform import rotate\n",
    "from skimage import exposure\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformation Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_with_rotation(image,degree):\n",
    "    return rotate(image, degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def horizontal_flip(image):\n",
    "    return image[:, ::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vertical_flip(image):\n",
    "    return image[::-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def better_contrast(image):\n",
    "    v_min, v_max = np.percentile(image, (0.2, 99.8))\n",
    "    return exposure.rescale_intensity(image, in_range=(v_min, v_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below Augmentation is done sequentially on train data so labels in rotated_image,hori_flip,etc. are retained in the order of training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rotated_image=[]\n",
    "hori_flip=[]\n",
    "verti_flip=[]\n",
    "better_cont=[]\n",
    "for i in range(0,60000):\n",
    "    image=train_x[:,i].reshape((28,28))\n",
    "    rotated_image.append(image_with_rotation(image,90))\n",
    "    hori_flip.append(horizontal_flip(image))\n",
    "    verti_flip.append(vertical_flip(image))\n",
    "    better_cont.append(better_contrast(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt.imshow(np.array(better_cont)[2].reshape((28,28)),interpolation='nearest',cmap='gray')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshaping in conventional Form\n",
    "rotated_image=np.array(rotated_image).reshape((60000,-1)).T\n",
    "hori_flip=np.array(hori_flip).reshape((60000,-1)).T\n",
    "verti_flip=np.array(verti_flip).reshape((60000,-1)).T\n",
    "better_cont=np.array(better_cont).reshape((60000,-1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=np.concatenate((train_x,rotated_image),axis=1)\n",
    "train_x=np.concatenate((train_x,hori_flip),axis=1)\n",
    "train_x=np.concatenate((train_x,verti_flip),axis=1)\n",
    "train_x=np.concatenate((train_x,better_cont),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_temp=train_y.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y=np.concatenate((train_y,train_y_temp),axis=1)\n",
    "train_y=np.concatenate((train_y,train_y_temp),axis=1)\n",
    "train_y=np.concatenate((train_y,train_y_temp),axis=1)\n",
    "train_y=np.concatenate((train_y,train_y_temp),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing\n",
    "train_x=train_x/255\n",
    "test_x=test_x/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part -2\n",
    "#### Build a CNN network from scratch using tensorflow on transformed data with highest validation accuracy & use that  model for inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No Dropout and Mini batch Input.Trained for subset of data from row 30k to 90k.And fed randomly to the network using batch sie of 128."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A 'nan' value for Minibatch Loss came when whole data was used as input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_iters = 200000\n",
    "batch_size = 128\n",
    "display_step = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Parameters\n",
    "n_input = 784  # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "dropout = 1. # Dropout, probability to keep units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32)  # dropout (keep probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some wrappers for simplicity\n",
    "def conv2d(x, W, b, strides=1):\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpool2d(x, k=2):\n",
    "    # MaxPool2D wrapper\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n",
    "                          padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "def conv_net(x, weights, biases, dropout):\n",
    "    # Reshape input picture\n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "\n",
    "    # Fully connected layer\n",
    "    # Reshape conv2 output to fit fully connected layer input\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    # Apply Dropout\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    # Output, class prediction\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "\n",
    "weights = {\n",
    "    # 5x5 conv, 1 input, 32 outputs\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    # 5x5 conv, 32 inputs, 64 outputs\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    # fully connected, 7*7*64 inputs, 1024 outputs\n",
    "    'wd1': tf.Variable(tf.random_normal([7 * 7 * 64, 1024])),\n",
    "    # 1024 inputs, 10 outputs (class prediction)\n",
    "    'out': tf.Variable(tf.random_normal([1024, n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct model\n",
    "pred = conv_net(x, weights, biases, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = 10 # No. of Classes\n",
    "m=300000 #Training Instances\n",
    "\n",
    "Y_new = np.eye(digits)[train_y.astype('int32')]\n",
    "Y_new = Y_new.T.reshape(digits,m)\n",
    "Y_test = np.eye(digits)[test_y.astype('int32')]\n",
    "Y_test = Y_test.T.reshape(digits,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_=train_x.T[30000:90000,:]\n",
    "y_=Y_new.T[30000:90000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1280, Minibatch Loss= 11336.228516, Training Accuracy= 0.21094\n",
      "Iter 2560, Minibatch Loss= 8748.800781, Training Accuracy= 0.30469\n",
      "Iter 3840, Minibatch Loss= 3673.313232, Training Accuracy= 0.43750\n",
      "Iter 5120, Minibatch Loss= 3067.991699, Training Accuracy= 0.40625\n",
      "Iter 6400, Minibatch Loss= 3062.059082, Training Accuracy= 0.39844\n",
      "Iter 7680, Minibatch Loss= 2279.008789, Training Accuracy= 0.44531\n",
      "Iter 8960, Minibatch Loss= 3268.207520, Training Accuracy= 0.43750\n",
      "Iter 10240, Minibatch Loss= 3904.333984, Training Accuracy= 0.45312\n",
      "Iter 11520, Minibatch Loss= 3580.645264, Training Accuracy= 0.33594\n",
      "Iter 12800, Minibatch Loss= 2624.833740, Training Accuracy= 0.42188\n",
      "Iter 14080, Minibatch Loss= 3450.515625, Training Accuracy= 0.44531\n",
      "Iter 15360, Minibatch Loss= 2452.075195, Training Accuracy= 0.46094\n",
      "Iter 16640, Minibatch Loss= 2297.759033, Training Accuracy= 0.37500\n",
      "Iter 17920, Minibatch Loss= 3523.083984, Training Accuracy= 0.34375\n",
      "Iter 19200, Minibatch Loss= 2352.276367, Training Accuracy= 0.46094\n",
      "Iter 20480, Minibatch Loss= 2417.407227, Training Accuracy= 0.36719\n",
      "Iter 21760, Minibatch Loss= 2090.541504, Training Accuracy= 0.40625\n",
      "Iter 23040, Minibatch Loss= 3306.607666, Training Accuracy= 0.35938\n",
      "Iter 24320, Minibatch Loss= 2046.281006, Training Accuracy= 0.45312\n",
      "Iter 25600, Minibatch Loss= 3452.497314, Training Accuracy= 0.33594\n",
      "Iter 26880, Minibatch Loss= 2007.490967, Training Accuracy= 0.43750\n",
      "Iter 28160, Minibatch Loss= 1853.911011, Training Accuracy= 0.47656\n",
      "Iter 29440, Minibatch Loss= 2781.369141, Training Accuracy= 0.44531\n",
      "Iter 30720, Minibatch Loss= 2405.521240, Training Accuracy= 0.44531\n",
      "Iter 32000, Minibatch Loss= 2407.134277, Training Accuracy= 0.42188\n",
      "Iter 33280, Minibatch Loss= 1958.009644, Training Accuracy= 0.43750\n",
      "Iter 34560, Minibatch Loss= 2604.023193, Training Accuracy= 0.44531\n",
      "Iter 35840, Minibatch Loss= 1708.426025, Training Accuracy= 0.46875\n",
      "Iter 37120, Minibatch Loss= 2928.851074, Training Accuracy= 0.41406\n",
      "Iter 38400, Minibatch Loss= 2566.766602, Training Accuracy= 0.42188\n",
      "Iter 39680, Minibatch Loss= 3017.630127, Training Accuracy= 0.35938\n",
      "Iter 40960, Minibatch Loss= 2708.885254, Training Accuracy= 0.40625\n",
      "Iter 42240, Minibatch Loss= 1954.937134, Training Accuracy= 0.50000\n",
      "Iter 43520, Minibatch Loss= 2639.997559, Training Accuracy= 0.39844\n",
      "Iter 44800, Minibatch Loss= 1638.330200, Training Accuracy= 0.46094\n",
      "Iter 46080, Minibatch Loss= 1545.796631, Training Accuracy= 0.43750\n",
      "Iter 47360, Minibatch Loss= 3024.536377, Training Accuracy= 0.44531\n",
      "Iter 48640, Minibatch Loss= 2301.671875, Training Accuracy= 0.40625\n",
      "Iter 49920, Minibatch Loss= 2106.597656, Training Accuracy= 0.47656\n",
      "Iter 51200, Minibatch Loss= 2225.231934, Training Accuracy= 0.45312\n",
      "Iter 52480, Minibatch Loss= 1934.730103, Training Accuracy= 0.46875\n",
      "Iter 53760, Minibatch Loss= 3127.929199, Training Accuracy= 0.39844\n",
      "Iter 55040, Minibatch Loss= 1978.452881, Training Accuracy= 0.39844\n",
      "Iter 56320, Minibatch Loss= 1691.375732, Training Accuracy= 0.42969\n",
      "Iter 57600, Minibatch Loss= 1851.497192, Training Accuracy= 0.45312\n",
      "Iter 58880, Minibatch Loss= 2282.870117, Training Accuracy= 0.39062\n",
      "Iter 60160, Minibatch Loss= 2088.418701, Training Accuracy= 0.43750\n",
      "Iter 61440, Minibatch Loss= 985.696106, Training Accuracy= 0.42969\n",
      "Iter 62720, Minibatch Loss= 1731.723389, Training Accuracy= 0.45312\n",
      "Iter 64000, Minibatch Loss= 1522.942871, Training Accuracy= 0.46094\n",
      "Iter 65280, Minibatch Loss= 1605.214355, Training Accuracy= 0.46094\n",
      "Iter 66560, Minibatch Loss= 1790.948364, Training Accuracy= 0.43750\n",
      "Iter 67840, Minibatch Loss= 1134.057739, Training Accuracy= 0.49219\n",
      "Iter 69120, Minibatch Loss= 1696.651001, Training Accuracy= 0.44531\n",
      "Iter 70400, Minibatch Loss= 1998.987915, Training Accuracy= 0.45312\n",
      "Iter 71680, Minibatch Loss= 1881.489990, Training Accuracy= 0.48438\n",
      "Iter 72960, Minibatch Loss= 1547.380371, Training Accuracy= 0.49219\n",
      "Iter 74240, Minibatch Loss= 967.285156, Training Accuracy= 0.52344\n",
      "Iter 75520, Minibatch Loss= 1962.824585, Training Accuracy= 0.46094\n",
      "Iter 76800, Minibatch Loss= 2540.626953, Training Accuracy= 0.39062\n",
      "Iter 78080, Minibatch Loss= 1969.801514, Training Accuracy= 0.41406\n",
      "Iter 79360, Minibatch Loss= 2383.886230, Training Accuracy= 0.38281\n",
      "Iter 80640, Minibatch Loss= 1341.963745, Training Accuracy= 0.43750\n",
      "Iter 81920, Minibatch Loss= 1987.983398, Training Accuracy= 0.44531\n",
      "Iter 83200, Minibatch Loss= 1306.074463, Training Accuracy= 0.43750\n",
      "Iter 84480, Minibatch Loss= 1535.939209, Training Accuracy= 0.46875\n",
      "Iter 85760, Minibatch Loss= 1558.248657, Training Accuracy= 0.42969\n",
      "Iter 87040, Minibatch Loss= 1843.535278, Training Accuracy= 0.38281\n",
      "Iter 88320, Minibatch Loss= 1740.742920, Training Accuracy= 0.43750\n",
      "Iter 89600, Minibatch Loss= 1538.152954, Training Accuracy= 0.47656\n",
      "Iter 90880, Minibatch Loss= 1652.682007, Training Accuracy= 0.41406\n",
      "Iter 92160, Minibatch Loss= 1560.781006, Training Accuracy= 0.40625\n",
      "Iter 93440, Minibatch Loss= 1150.369141, Training Accuracy= 0.50781\n",
      "Iter 94720, Minibatch Loss= 2088.874512, Training Accuracy= 0.44531\n",
      "Iter 96000, Minibatch Loss= 1662.844116, Training Accuracy= 0.40625\n",
      "Iter 97280, Minibatch Loss= 1308.475830, Training Accuracy= 0.39844\n",
      "Iter 98560, Minibatch Loss= 1629.663818, Training Accuracy= 0.42188\n",
      "Iter 99840, Minibatch Loss= 1051.814697, Training Accuracy= 0.47656\n",
      "Iter 101120, Minibatch Loss= 1496.675537, Training Accuracy= 0.42188\n",
      "Iter 102400, Minibatch Loss= 1051.903564, Training Accuracy= 0.43750\n",
      "Iter 103680, Minibatch Loss= 1301.059814, Training Accuracy= 0.42188\n",
      "Iter 104960, Minibatch Loss= 1502.535522, Training Accuracy= 0.46094\n",
      "Iter 106240, Minibatch Loss= 1327.379761, Training Accuracy= 0.45312\n",
      "Iter 107520, Minibatch Loss= 1443.794434, Training Accuracy= 0.43750\n",
      "Iter 108800, Minibatch Loss= 1495.368530, Training Accuracy= 0.50781\n",
      "Iter 110080, Minibatch Loss= 1281.508545, Training Accuracy= 0.46094\n",
      "Iter 111360, Minibatch Loss= 1751.974854, Training Accuracy= 0.45312\n",
      "Iter 112640, Minibatch Loss= 726.081421, Training Accuracy= 0.51562\n",
      "Iter 113920, Minibatch Loss= 1293.468750, Training Accuracy= 0.43750\n",
      "Iter 115200, Minibatch Loss= 1085.464355, Training Accuracy= 0.46094\n",
      "Iter 116480, Minibatch Loss= 820.479614, Training Accuracy= 0.48438\n",
      "Iter 117760, Minibatch Loss= 1360.822021, Training Accuracy= 0.53906\n",
      "Iter 119040, Minibatch Loss= 1019.101562, Training Accuracy= 0.50000\n",
      "Iter 120320, Minibatch Loss= 1331.042236, Training Accuracy= 0.47656\n",
      "Iter 121600, Minibatch Loss= 1220.110596, Training Accuracy= 0.53125\n",
      "Iter 122880, Minibatch Loss= 973.122375, Training Accuracy= 0.50781\n",
      "Iter 124160, Minibatch Loss= 1411.734985, Training Accuracy= 0.43750\n",
      "Iter 125440, Minibatch Loss= 1240.825195, Training Accuracy= 0.47656\n",
      "Iter 126720, Minibatch Loss= 908.294617, Training Accuracy= 0.54688\n",
      "Iter 128000, Minibatch Loss= 1158.490479, Training Accuracy= 0.42969\n",
      "Iter 129280, Minibatch Loss= 1003.771851, Training Accuracy= 0.50000\n",
      "Iter 130560, Minibatch Loss= 1203.508911, Training Accuracy= 0.48438\n",
      "Iter 131840, Minibatch Loss= 1097.543701, Training Accuracy= 0.38281\n",
      "Iter 133120, Minibatch Loss= 1270.193848, Training Accuracy= 0.42969\n",
      "Iter 134400, Minibatch Loss= 1743.776611, Training Accuracy= 0.44531\n",
      "Iter 135680, Minibatch Loss= 1017.597107, Training Accuracy= 0.46094\n",
      "Iter 136960, Minibatch Loss= 1266.351807, Training Accuracy= 0.50781\n",
      "Iter 138240, Minibatch Loss= 1608.194946, Training Accuracy= 0.45312\n",
      "Iter 139520, Minibatch Loss= 837.737793, Training Accuracy= 0.41406\n",
      "Iter 140800, Minibatch Loss= 1137.341064, Training Accuracy= 0.42969\n",
      "Iter 142080, Minibatch Loss= 1179.348633, Training Accuracy= 0.40625\n",
      "Iter 143360, Minibatch Loss= 845.161255, Training Accuracy= 0.46875\n",
      "Iter 144640, Minibatch Loss= 2051.283447, Training Accuracy= 0.35156\n",
      "Iter 145920, Minibatch Loss= 1428.298096, Training Accuracy= 0.40625\n",
      "Iter 147200, Minibatch Loss= 1206.328369, Training Accuracy= 0.46094\n",
      "Iter 148480, Minibatch Loss= 1403.397705, Training Accuracy= 0.42188\n",
      "Iter 149760, Minibatch Loss= 663.848755, Training Accuracy= 0.49219\n",
      "Iter 151040, Minibatch Loss= 723.565674, Training Accuracy= 0.46094\n",
      "Iter 152320, Minibatch Loss= 803.199402, Training Accuracy= 0.42969\n",
      "Iter 153600, Minibatch Loss= 674.923828, Training Accuracy= 0.49219\n",
      "Iter 154880, Minibatch Loss= 919.612061, Training Accuracy= 0.41406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 156160, Minibatch Loss= 1358.777466, Training Accuracy= 0.42969\n",
      "Iter 157440, Minibatch Loss= 1173.561768, Training Accuracy= 0.49219\n",
      "Iter 158720, Minibatch Loss= 1000.932678, Training Accuracy= 0.43750\n",
      "Iter 160000, Minibatch Loss= 745.206238, Training Accuracy= 0.41406\n",
      "Iter 161280, Minibatch Loss= 701.792603, Training Accuracy= 0.56250\n",
      "Iter 162560, Minibatch Loss= 1100.536621, Training Accuracy= 0.42969\n",
      "Iter 163840, Minibatch Loss= 918.338867, Training Accuracy= 0.51562\n",
      "Iter 165120, Minibatch Loss= 705.562012, Training Accuracy= 0.47656\n",
      "Iter 166400, Minibatch Loss= 587.995972, Training Accuracy= 0.50781\n",
      "Iter 167680, Minibatch Loss= 598.442505, Training Accuracy= 0.46875\n",
      "Iter 168960, Minibatch Loss= 991.612122, Training Accuracy= 0.51562\n",
      "Iter 170240, Minibatch Loss= 919.793457, Training Accuracy= 0.51562\n",
      "Iter 171520, Minibatch Loss= 846.554810, Training Accuracy= 0.48438\n",
      "Iter 172800, Minibatch Loss= 884.922852, Training Accuracy= 0.42188\n",
      "Iter 174080, Minibatch Loss= 866.818115, Training Accuracy= 0.50000\n",
      "Iter 175360, Minibatch Loss= 1282.656982, Training Accuracy= 0.46875\n",
      "Iter 176640, Minibatch Loss= 1061.989746, Training Accuracy= 0.47656\n",
      "Iter 177920, Minibatch Loss= 1233.005493, Training Accuracy= 0.42969\n",
      "Iter 179200, Minibatch Loss= 601.289551, Training Accuracy= 0.47656\n",
      "Iter 180480, Minibatch Loss= 1218.656494, Training Accuracy= 0.49219\n",
      "Iter 181760, Minibatch Loss= 780.798218, Training Accuracy= 0.47656\n",
      "Iter 183040, Minibatch Loss= 413.262939, Training Accuracy= 0.50781\n",
      "Iter 184320, Minibatch Loss= 793.893066, Training Accuracy= 0.45312\n",
      "Iter 185600, Minibatch Loss= 853.700684, Training Accuracy= 0.50781\n",
      "Iter 186880, Minibatch Loss= 898.372559, Training Accuracy= 0.51562\n",
      "Iter 188160, Minibatch Loss= 699.561340, Training Accuracy= 0.41406\n",
      "Iter 189440, Minibatch Loss= 713.884399, Training Accuracy= 0.50000\n",
      "Iter 190720, Minibatch Loss= 623.202148, Training Accuracy= 0.48438\n",
      "Iter 192000, Minibatch Loss= 861.915161, Training Accuracy= 0.46875\n",
      "Iter 193280, Minibatch Loss= 705.737732, Training Accuracy= 0.48438\n",
      "Iter 194560, Minibatch Loss= 1285.625000, Training Accuracy= 0.42969\n",
      "Iter 195840, Minibatch Loss= 674.973633, Training Accuracy= 0.49219\n",
      "Iter 197120, Minibatch Loss= 665.070740, Training Accuracy= 0.48438\n",
      "Iter 198400, Minibatch Loss= 1096.517456, Training Accuracy= 0.42188\n",
      "Iter 199680, Minibatch Loss= 1336.318115, Training Accuracy= 0.46094\n",
      "Optimization Finished!\n",
      "Testing accuracy: 0.816\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    while step * batch_size < training_iters:\n",
    "        batch_x, batch_y = next_batch(batch_size,x_,y_)\n",
    "\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y,\n",
    "                                       keep_prob: dropout})\n",
    "        if step % display_step == 0:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x,\n",
    "                                                              y: batch_y,\n",
    "                                                              keep_prob: 1.})\n",
    "            print(\"Iter \" + str(step * batch_size) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(acc))\n",
    "        step += 1\n",
    "    print(\"Optimization Finished!\")\n",
    "    print('Testing accuracy:', sess.run(accuracy, feed_dict={x: test_x.T[:1000,:], y:Y_test.T[:1000,:], keep_prob:1.}))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part -3\n",
    "#### Modify the above architecture by using Batch normalization, dropout, ReduceLRonPlateau, Early stopping.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Dropout =0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_iters = 200000\n",
    "batch_size = 128\n",
    "display_step = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Parameters\n",
    "n_input = 784  # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "dropout = 0.50 # Dropout, probability to keep units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32)  # dropout (keep probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some wrappers for simplicity\n",
    "def conv2d(x, W, b, strides=1):\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpool2d(x, k=2):\n",
    "    # MaxPool2D wrapper\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n",
    "                          padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "def conv_net(x, weights, biases, dropout):\n",
    "    # Reshape input picture\n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "\n",
    "    # Fully connected layer\n",
    "    # Reshape conv2 output to fit fully connected layer input\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    # Apply Dropout\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    # Output, class prediction\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "\n",
    "weights = {\n",
    "    # 5x5 conv, 1 input, 32 outputs\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    # 5x5 conv, 32 inputs, 64 outputs\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    # fully connected, 7*7*64 inputs, 1024 outputs\n",
    "    'wd1': tf.Variable(tf.random_normal([7 * 7 * 64, 1024])),\n",
    "    # 1024 inputs, 10 outputs (class prediction)\n",
    "    'out': tf.Variable(tf.random_normal([1024, n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct model\n",
    "pred = conv_net(x, weights, biases, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = 10 # No. of Classes\n",
    "m=300000 #Training Instances\n",
    "\n",
    "Y_new = np.eye(digits)[train_y.astype('int32')]\n",
    "Y_new = Y_new.T.reshape(digits,m)\n",
    "Y_test = np.eye(digits)[test_y.astype('int32')]\n",
    "Y_test = Y_test.T.reshape(digits,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_=train_x.T[30000:90000,:]\n",
    "y_=Y_new.T[30000:90000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1280, Minibatch Loss= 11697.900391, Training Accuracy= 0.22656\n",
      "Iter 2560, Minibatch Loss= 6787.408691, Training Accuracy= 0.46094\n",
      "Iter 3840, Minibatch Loss= 6731.474121, Training Accuracy= 0.35938\n",
      "Iter 5120, Minibatch Loss= 5288.691406, Training Accuracy= 0.33594\n",
      "Iter 6400, Minibatch Loss= 3211.822998, Training Accuracy= 0.35938\n",
      "Iter 7680, Minibatch Loss= 3340.376221, Training Accuracy= 0.51562\n",
      "Iter 8960, Minibatch Loss= 2577.412598, Training Accuracy= 0.45312\n",
      "Iter 10240, Minibatch Loss= 3992.897217, Training Accuracy= 0.44531\n",
      "Iter 11520, Minibatch Loss= 1660.057373, Training Accuracy= 0.42188\n",
      "Iter 12800, Minibatch Loss= 3798.840088, Training Accuracy= 0.32031\n",
      "Iter 14080, Minibatch Loss= 2429.719971, Training Accuracy= 0.41406\n",
      "Iter 15360, Minibatch Loss= 2530.681641, Training Accuracy= 0.42969\n",
      "Iter 16640, Minibatch Loss= 2213.971680, Training Accuracy= 0.45312\n",
      "Iter 17920, Minibatch Loss= 1223.053467, Training Accuracy= 0.38281\n",
      "Iter 19200, Minibatch Loss= 1751.330078, Training Accuracy= 0.43750\n",
      "Iter 20480, Minibatch Loss= 1311.804688, Training Accuracy= 0.47656\n",
      "Iter 21760, Minibatch Loss= 2003.689941, Training Accuracy= 0.42969\n",
      "Iter 23040, Minibatch Loss= 1781.599243, Training Accuracy= 0.39844\n",
      "Iter 24320, Minibatch Loss= 2101.568359, Training Accuracy= 0.50781\n",
      "Iter 25600, Minibatch Loss= 963.353882, Training Accuracy= 0.53125\n",
      "Iter 26880, Minibatch Loss= 1873.958374, Training Accuracy= 0.39844\n",
      "Iter 28160, Minibatch Loss= 873.578003, Training Accuracy= 0.43750\n",
      "Iter 29440, Minibatch Loss= 1400.475586, Training Accuracy= 0.38281\n",
      "Iter 30720, Minibatch Loss= 640.891174, Training Accuracy= 0.48438\n",
      "Iter 32000, Minibatch Loss= 779.377075, Training Accuracy= 0.46875\n",
      "Iter 33280, Minibatch Loss= 422.546936, Training Accuracy= 0.53906\n",
      "Iter 34560, Minibatch Loss= 868.863770, Training Accuracy= 0.43750\n",
      "Iter 35840, Minibatch Loss= 1129.519043, Training Accuracy= 0.46094\n",
      "Iter 37120, Minibatch Loss= 740.125916, Training Accuracy= 0.48438\n",
      "Iter 38400, Minibatch Loss= 774.394043, Training Accuracy= 0.42188\n",
      "Iter 39680, Minibatch Loss= 1107.370239, Training Accuracy= 0.42188\n",
      "Iter 40960, Minibatch Loss= 605.543335, Training Accuracy= 0.46875\n",
      "Iter 42240, Minibatch Loss= 895.869751, Training Accuracy= 0.44531\n",
      "Iter 43520, Minibatch Loss= 657.150269, Training Accuracy= 0.47656\n",
      "Iter 44800, Minibatch Loss= 796.988281, Training Accuracy= 0.46094\n",
      "Iter 46080, Minibatch Loss= 763.562866, Training Accuracy= 0.46094\n",
      "Iter 47360, Minibatch Loss= 455.744934, Training Accuracy= 0.40625\n",
      "Iter 48640, Minibatch Loss= 382.318451, Training Accuracy= 0.40625\n",
      "Iter 49920, Minibatch Loss= 568.090088, Training Accuracy= 0.54688\n",
      "Iter 51200, Minibatch Loss= 742.379150, Training Accuracy= 0.42969\n",
      "Iter 52480, Minibatch Loss= 596.598999, Training Accuracy= 0.43750\n",
      "Iter 53760, Minibatch Loss= 784.108398, Training Accuracy= 0.49219\n",
      "Iter 55040, Minibatch Loss= 674.316467, Training Accuracy= 0.42188\n",
      "Iter 56320, Minibatch Loss= 656.886902, Training Accuracy= 0.47656\n",
      "Iter 57600, Minibatch Loss= 817.790222, Training Accuracy= 0.41406\n",
      "Iter 58880, Minibatch Loss= 735.279541, Training Accuracy= 0.39844\n",
      "Iter 60160, Minibatch Loss= 355.257751, Training Accuracy= 0.48438\n",
      "Iter 61440, Minibatch Loss= 492.414124, Training Accuracy= 0.46875\n",
      "Iter 62720, Minibatch Loss= 396.053619, Training Accuracy= 0.39844\n",
      "Iter 64000, Minibatch Loss= 519.214478, Training Accuracy= 0.46875\n",
      "Iter 65280, Minibatch Loss= 450.348206, Training Accuracy= 0.50781\n",
      "Iter 66560, Minibatch Loss= 498.389587, Training Accuracy= 0.44531\n",
      "Iter 67840, Minibatch Loss= 602.047607, Training Accuracy= 0.40625\n",
      "Iter 69120, Minibatch Loss= 312.007263, Training Accuracy= 0.42969\n",
      "Iter 70400, Minibatch Loss= 363.173615, Training Accuracy= 0.42969\n",
      "Iter 71680, Minibatch Loss= 439.098633, Training Accuracy= 0.46094\n",
      "Iter 72960, Minibatch Loss= 251.427017, Training Accuracy= 0.42969\n",
      "Iter 74240, Minibatch Loss= 191.525604, Training Accuracy= 0.50000\n",
      "Iter 75520, Minibatch Loss= 172.618530, Training Accuracy= 0.52344\n",
      "Iter 76800, Minibatch Loss= 287.207977, Training Accuracy= 0.52344\n",
      "Iter 78080, Minibatch Loss= 370.609070, Training Accuracy= 0.42188\n",
      "Iter 79360, Minibatch Loss= 401.775818, Training Accuracy= 0.41406\n",
      "Iter 80640, Minibatch Loss= 260.006531, Training Accuracy= 0.46094\n",
      "Iter 81920, Minibatch Loss= 203.892395, Training Accuracy= 0.45312\n",
      "Iter 83200, Minibatch Loss= 610.139709, Training Accuracy= 0.42188\n",
      "Iter 84480, Minibatch Loss= 285.992249, Training Accuracy= 0.46875\n",
      "Iter 85760, Minibatch Loss= 393.163391, Training Accuracy= 0.52344\n",
      "Iter 87040, Minibatch Loss= 246.187271, Training Accuracy= 0.45312\n",
      "Iter 88320, Minibatch Loss= 339.358063, Training Accuracy= 0.41406\n",
      "Iter 89600, Minibatch Loss= 279.212433, Training Accuracy= 0.52344\n",
      "Iter 90880, Minibatch Loss= 239.967575, Training Accuracy= 0.46875\n",
      "Iter 92160, Minibatch Loss= 223.777893, Training Accuracy= 0.46094\n",
      "Iter 93440, Minibatch Loss= 205.223862, Training Accuracy= 0.42969\n",
      "Iter 94720, Minibatch Loss= 192.418533, Training Accuracy= 0.37500\n",
      "Iter 96000, Minibatch Loss= 140.444839, Training Accuracy= 0.56250\n",
      "Iter 97280, Minibatch Loss= 301.849304, Training Accuracy= 0.50000\n",
      "Iter 98560, Minibatch Loss= 273.900726, Training Accuracy= 0.48438\n",
      "Iter 99840, Minibatch Loss= 36.463551, Training Accuracy= 0.46875\n",
      "Iter 101120, Minibatch Loss= 270.946991, Training Accuracy= 0.35938\n",
      "Iter 102400, Minibatch Loss= 204.596985, Training Accuracy= 0.43750\n",
      "Iter 103680, Minibatch Loss= 135.576019, Training Accuracy= 0.45312\n",
      "Iter 104960, Minibatch Loss= 289.751221, Training Accuracy= 0.45312\n",
      "Iter 106240, Minibatch Loss= 157.093384, Training Accuracy= 0.43750\n",
      "Iter 107520, Minibatch Loss= 203.868347, Training Accuracy= 0.46094\n",
      "Iter 108800, Minibatch Loss= 231.166183, Training Accuracy= 0.44531\n",
      "Iter 110080, Minibatch Loss= 273.125916, Training Accuracy= 0.46094\n",
      "Iter 111360, Minibatch Loss= 254.651276, Training Accuracy= 0.39062\n",
      "Iter 112640, Minibatch Loss= 64.033188, Training Accuracy= 0.48438\n",
      "Iter 113920, Minibatch Loss= 179.239105, Training Accuracy= 0.46875\n",
      "Iter 115200, Minibatch Loss= 189.434921, Training Accuracy= 0.44531\n",
      "Iter 116480, Minibatch Loss= 135.253006, Training Accuracy= 0.42969\n",
      "Iter 117760, Minibatch Loss= 79.912567, Training Accuracy= 0.40625\n",
      "Iter 119040, Minibatch Loss= 210.295364, Training Accuracy= 0.46094\n",
      "Iter 120320, Minibatch Loss= 160.715088, Training Accuracy= 0.46094\n",
      "Iter 121600, Minibatch Loss= 145.842072, Training Accuracy= 0.51562\n",
      "Iter 122880, Minibatch Loss= 234.362793, Training Accuracy= 0.44531\n",
      "Iter 124160, Minibatch Loss= 114.404572, Training Accuracy= 0.40625\n",
      "Iter 125440, Minibatch Loss= 147.846176, Training Accuracy= 0.35938\n",
      "Iter 126720, Minibatch Loss= 88.680298, Training Accuracy= 0.48438\n",
      "Iter 128000, Minibatch Loss= 98.110901, Training Accuracy= 0.45312\n",
      "Iter 129280, Minibatch Loss= 128.824951, Training Accuracy= 0.46094\n",
      "Iter 130560, Minibatch Loss= 70.125244, Training Accuracy= 0.42969\n",
      "Iter 131840, Minibatch Loss= 76.492317, Training Accuracy= 0.41406\n",
      "Iter 133120, Minibatch Loss= 71.936096, Training Accuracy= 0.45312\n",
      "Iter 134400, Minibatch Loss= 64.800064, Training Accuracy= 0.46875\n",
      "Iter 135680, Minibatch Loss= 98.767616, Training Accuracy= 0.42188\n",
      "Iter 136960, Minibatch Loss= 169.113617, Training Accuracy= 0.57812\n",
      "Iter 138240, Minibatch Loss= 178.342850, Training Accuracy= 0.46875\n",
      "Iter 139520, Minibatch Loss= 148.602203, Training Accuracy= 0.42969\n",
      "Iter 140800, Minibatch Loss= 39.158310, Training Accuracy= 0.42969\n",
      "Iter 142080, Minibatch Loss= 140.896729, Training Accuracy= 0.33594\n",
      "Iter 143360, Minibatch Loss= 73.264008, Training Accuracy= 0.40625\n",
      "Iter 144640, Minibatch Loss= 118.431992, Training Accuracy= 0.45312\n",
      "Iter 145920, Minibatch Loss= 103.236465, Training Accuracy= 0.46875\n",
      "Iter 147200, Minibatch Loss= 64.757179, Training Accuracy= 0.43750\n",
      "Iter 148480, Minibatch Loss= 121.693001, Training Accuracy= 0.41406\n",
      "Iter 149760, Minibatch Loss= 40.462135, Training Accuracy= 0.43750\n",
      "Iter 151040, Minibatch Loss= 46.106228, Training Accuracy= 0.42188\n",
      "Iter 152320, Minibatch Loss= 48.556778, Training Accuracy= 0.48438\n",
      "Iter 153600, Minibatch Loss= 50.094753, Training Accuracy= 0.48438\n",
      "Iter 154880, Minibatch Loss= 65.750854, Training Accuracy= 0.40625\n",
      "Iter 156160, Minibatch Loss= 58.788296, Training Accuracy= 0.38281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 157440, Minibatch Loss= 64.269020, Training Accuracy= 0.46875\n",
      "Iter 158720, Minibatch Loss= 76.939682, Training Accuracy= 0.38281\n",
      "Iter 160000, Minibatch Loss= 70.889816, Training Accuracy= 0.48438\n",
      "Iter 161280, Minibatch Loss= 50.163727, Training Accuracy= 0.49219\n",
      "Iter 162560, Minibatch Loss= 59.067192, Training Accuracy= 0.52344\n",
      "Iter 163840, Minibatch Loss= 67.853897, Training Accuracy= 0.40625\n",
      "Iter 165120, Minibatch Loss= 72.254372, Training Accuracy= 0.43750\n",
      "Iter 166400, Minibatch Loss= 43.169518, Training Accuracy= 0.40625\n",
      "Iter 167680, Minibatch Loss= 120.090584, Training Accuracy= 0.42969\n",
      "Iter 168960, Minibatch Loss= 35.850197, Training Accuracy= 0.39844\n",
      "Iter 170240, Minibatch Loss= 68.601608, Training Accuracy= 0.45312\n",
      "Iter 171520, Minibatch Loss= 40.715919, Training Accuracy= 0.42188\n",
      "Iter 172800, Minibatch Loss= 53.471359, Training Accuracy= 0.38281\n",
      "Iter 174080, Minibatch Loss= 47.087692, Training Accuracy= 0.45312\n",
      "Iter 175360, Minibatch Loss= 33.706306, Training Accuracy= 0.39062\n",
      "Iter 176640, Minibatch Loss= 36.608223, Training Accuracy= 0.38281\n",
      "Iter 177920, Minibatch Loss= 24.917173, Training Accuracy= 0.41406\n",
      "Iter 179200, Minibatch Loss= 37.799034, Training Accuracy= 0.46875\n",
      "Iter 180480, Minibatch Loss= 23.564428, Training Accuracy= 0.30469\n",
      "Iter 181760, Minibatch Loss= 13.188089, Training Accuracy= 0.29688\n",
      "Iter 183040, Minibatch Loss= 28.002951, Training Accuracy= 0.38281\n",
      "Iter 184320, Minibatch Loss= 26.255978, Training Accuracy= 0.46094\n",
      "Iter 185600, Minibatch Loss= 15.819749, Training Accuracy= 0.39844\n",
      "Iter 186880, Minibatch Loss= 7.774899, Training Accuracy= 0.38281\n",
      "Iter 188160, Minibatch Loss= 24.831409, Training Accuracy= 0.42188\n",
      "Iter 189440, Minibatch Loss= 16.991209, Training Accuracy= 0.34375\n",
      "Iter 190720, Minibatch Loss= 26.530495, Training Accuracy= 0.33594\n",
      "Iter 192000, Minibatch Loss= 15.740505, Training Accuracy= 0.35938\n",
      "Iter 193280, Minibatch Loss= 62.828484, Training Accuracy= 0.34375\n",
      "Iter 194560, Minibatch Loss= 15.355296, Training Accuracy= 0.39844\n",
      "Iter 195840, Minibatch Loss= 15.241681, Training Accuracy= 0.40625\n",
      "Iter 197120, Minibatch Loss= 23.086128, Training Accuracy= 0.35156\n",
      "Iter 198400, Minibatch Loss= 41.591209, Training Accuracy= 0.35156\n",
      "Iter 199680, Minibatch Loss= 15.119894, Training Accuracy= 0.25781\n",
      "Optimization Finished!\n",
      "Testing accuracy: 0.609\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    while step * batch_size < training_iters:\n",
    "        batch_x, batch_y = next_batch(batch_size,x_,y_)\n",
    "\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y,\n",
    "                                       keep_prob: dropout})\n",
    "        if step % display_step == 0:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x,\n",
    "                                                              y: batch_y,\n",
    "                                                              keep_prob: 1.})\n",
    "            print(\"Iter \" + str(step * batch_size) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(acc))\n",
    "        step += 1\n",
    "    print(\"Optimization Finished!\")\n",
    "    print('Testing accuracy:', sess.run(accuracy, feed_dict={x: test_x.T[:1000,:], y:Y_test.T[:1000,:], keep_prob:1.}))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
